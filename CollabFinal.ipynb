{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CollabFinal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxaXsbHhGOfDFfYIPlmzMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshumanJain101/RecommendationCollaborative/blob/main/CollabFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpYi-vMqDWwa"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import sys\r\n",
        "from math import sqrt\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.metrics import mean_absolute_error\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from scipy import sparse"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p34aEJR4FiZK",
        "outputId": "20462d45-c873-4603-eaa0-8eb4ca29c1fd"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WVZBYKbFjOY"
      },
      "source": [
        "from __future__ import (absolute_import, division, print_function,             \r\n",
        "                        unicode_literals)                                      \r\n",
        "import pickle\r\n",
        "import os\r\n",
        "from surprise import KNNBasic\r\n",
        "from surprise import Dataset                                                     \r\n",
        "from surprise import Reader                                                      \r\n",
        "from surprise.model_selection import PredefinedKFold\r\n",
        "from surprise import dump\r\n",
        "from surprise.accuracy import rmse\r\n",
        "from surprise.accuracy import mae\r\n",
        "from surprise import SVD\r\n",
        "import os"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmP8va3lDjFP",
        "outputId": "eddd1cfc-ed07-4387-b131-19660baf5838"
      },
      "source": [
        "# df is dataframe\r\n",
        "df = pd.read_csv('ratings.csv', ',')\r\n",
        "print(df.head())\r\n",
        "\r\n",
        "n_users = df.userId.unique().shape[0]\r\n",
        "n_items = df.movieId.unique().shape[0]\r\n",
        "print ('Total Users : '+ str(n_users))\r\n",
        "print('Total Movie : ' + str(n_items))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "Total Users : 610\n",
            "Total Movie : 9724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VEGV5YmDoir",
        "outputId": "1438937e-cf9e-4a93-84e0-99c825440a35"
      },
      "source": [
        "# converting data frame to utility matrix .\r\n",
        "df_utility = df.pivot(index = 'userId',columns='movieId',values = 'rating').fillna(0)\r\n",
        "print(df_utility.head())\r\n",
        "\r\n",
        "#creating numpy array from pandas dataframe cz it provides better computn\r\n",
        "\r\n",
        "ratings = np.array(df_utility)\r\n",
        "# ratings numpy utility matrix\r\n",
        "\r\n",
        "print(ratings)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movieId  1       2       3       4       ...  193583  193585  193587  193609\n",
            "userId                                   ...                                \n",
            "1           4.0     0.0     4.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "2           0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "3           0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "4           0.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "5           4.0     0.0     0.0     0.0  ...     0.0     0.0     0.0     0.0\n",
            "\n",
            "[5 rows x 9724 columns]\n",
            "[[4.  0.  4.  ... 0.  0.  0. ]\n",
            " [0.  0.  0.  ... 0.  0.  0. ]\n",
            " [0.  0.  0.  ... 0.  0.  0. ]\n",
            " ...\n",
            " [2.5 2.  2.  ... 0.  0.  0. ]\n",
            " [3.  0.  0.  ... 0.  0.  0. ]\n",
            " [5.  0.  0.  ... 0.  0.  0. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLHV3KqeDrpz"
      },
      "source": [
        "def pearson_sim(mat):\r\n",
        "  sim_matrix = np.zeros((mat.shape[0],mat.shape[1]))\r\n",
        "  #print(mat.shape[0])\r\n",
        "  mean = np.mean(mat,axis=1)\r\n",
        "  #print(mean)\r\n",
        "  for user in range(mat.shape[0]):\r\n",
        "    nonzeroarr = mat[user,:].nonzero()[0]\r\n",
        "    #print(nonzeroarr)\r\n",
        "    avg = np.sum(mat[user])/len(nonzeroarr)\r\n",
        "    #print(avg)\r\n",
        "    sim_matrix[user,nonzeroarr] = mat[user,nonzeroarr] - avg + 1e-9\r\n",
        "\t\r\n",
        "  sim_matrix = (sim_matrix).dot((sim_matrix).T)\r\n",
        "  #print(sim_matrix)\r\n",
        "  norms = np.array([np.sqrt(np.diagonal(np.abs(sim_matrix)))])\r\n",
        "  #print(norms)\r\n",
        "\t# norms is a square root array of magnitude of each user (diagonal contains magntitude of rows)\r\n",
        "  #print(sim_matrix / norms / norms.T)\r\n",
        "  return (sim_matrix / norms / norms.T)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPuSecRED-a7"
      },
      "source": [
        "  # nonzeroarr = ratings[2,:].nonzero()[0]\r\n",
        "  # print(nonzeroarr)\r\n",
        "  # nonzerolen = len(nonzeroarr)\r\n",
        "  # print(nonzerolen)\r\n",
        "  # test_rating_indices = np.random.choice(nonzeroarr,size=int(nonzerolen*0.10),replace=False)\r\n",
        "  # print(test_rating_indices) \r\n",
        "  # the cocept of splitting is ki 10 maan lo ratings maine train mai 0 kr di aur unke corresponding test mai daal di  \r\n",
        "  def train_test_split(ratings,fractionTest):\r\n",
        "    test = np.zeros(ratings.shape)\r\n",
        "        \r\n",
        "    train = ratings.copy()\r\n",
        "    for user in range(ratings.shape[0]):\r\n",
        "      nonzeroarr = ratings[user,:].nonzero()[0]\r\n",
        "      # print(nonzeroarr[0])\r\n",
        "      nonzerolen = len(nonzeroarr)\r\n",
        "      # print(nonzerolen)\r\n",
        "      test_rating_indices = np.random.choice(nonzeroarr,size=int(nonzerolen*fractionTest),replace=False)\r\n",
        "      #training_rating_ind = np.random.choice(nonzeroarr,size=int(nonzerolen*(1-fractionTest)),replace=False)\r\n",
        "      train[user,test_rating_indices]=0\r\n",
        "      test[user,test_rating_indices] = ratings[user,test_rating_indices]\r\n",
        "\r\n",
        "    assert(np.all((train*test)==0))\r\n",
        "    return train,test"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTmmEKvFEBmq"
      },
      "source": [
        "def predict(ratings,similarity):\r\n",
        "\t# Summation sim(u,u')*r(u',i) / Summation of |sim(u,u')|\r\n",
        "  #den2=np.array(np.abs(similarity)).T\r\n",
        "  #print(den2)\r\n",
        "  den = np.array(np.abs(similarity).sum(axis=1)).T\r\n",
        "  #print(den)\r\n",
        "  den = den.reshape((den.shape[0],1))\r\n",
        "  #print(similarity.dot(ratings))\r\n",
        "  return similarity.dot(ratings) /den"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1tVbG6EGav"
      },
      "source": [
        "def predict_better(ratings,similarity):\r\n",
        "\t# r(ui) = ravg(u) + sum((sim(u,u')*(ru'i - ravgu'))/sum(sim(u,u'))\r\n",
        "  user_bias = ratings.mean(axis=1)\r\n",
        "  pred2= user_bias[:, np.newaxis]\r\n",
        "  #print(pred2)\r\n",
        "  ratings = (ratings - user_bias[:, np.newaxis]).copy()\r\n",
        "  pred = similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\r\n",
        "  pred += user_bias[:, np.newaxis]\r\n",
        "  return pred"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49KMp6ekFKZG"
      },
      "source": [
        "def get_rmse(pred, actual):\r\n",
        "    # Ignore zero terms.\r\n",
        "    pred = pred[actual.nonzero()].flatten()\r\n",
        "    actual = actual[actual.nonzero()].flatten()\r\n",
        "    return sqrt(mean_squared_error(pred, actual))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxKU3bSTFNVk"
      },
      "source": [
        "def get_mae(pred, actual):\r\n",
        "    # Ignore zero terms.\r\n",
        "    pred = pred[actual.nonzero()].flatten()\r\n",
        "    actual = actual[actual.nonzero()].flatten()\r\n",
        "    return mean_absolute_error(pred, actual)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlLSLiR3FY20"
      },
      "source": [
        "#reason for taking k as 50 ki maine try kiya and this was giving best result\r\n",
        "\r\n",
        "def predict_topk(ratings,similarity,k=50,bias=0):\r\n",
        "\r\n",
        "    # make new similarity matrix having only top k similar users\r\n",
        "    pred = np.zeros(ratings.shape)\r\n",
        "    new_sim = np.zeros(similarity.shape)\r\n",
        "    \r\n",
        "    for i in range(similarity.shape[0]):\r\n",
        "        x = tuple(np.sort(np.argsort(similarity[:,i])[:-k-1:-1]))\r\n",
        "        new_sim[i][[x]] = similarity[i][[x]]\r\n",
        "     \r\n",
        "    return predict_better(ratings,new_sim)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "GdYLGcClGGHa",
        "outputId": "9e42c892-82f8-4e8d-a4a0-a2c8da5be90c"
      },
      "source": [
        "split_ratio = [0.30]\r\n",
        "MAE_pb = []\r\n",
        "for split in split_ratio:\r\n",
        "    print(\"****************************************************************\\n\\n\\n\\n\")\r\n",
        "    print(\"split = \")\r\n",
        "    print(split)\r\n",
        "    #print(\"\\n\\n\\n\")\r\n",
        "    train,test = train_test_split(ratings,split) \r\n",
        "    #print('Data splitted into Train,Test')\r\n",
        "    #print(train)\r\n",
        "    sim_matrix = pearson_sim(train)\r\n",
        "    #sim_matrix2= train(method='pearson')\r\n",
        "    #print(sim_matrix)\r\n",
        "    #print(test)\r\n",
        "    algo = KNNBasic(sim_options = {'name':'pearson','user_based': True})\r\n",
        "\r\n",
        "    Dataset.load_builtin('ml-100k')\r\n",
        "\r\n",
        "    train_file = os.path.expanduser('~') + '/.surprise_data/ml-100k/ml-100k/u1.base'\r\n",
        "    test_file = os.path.expanduser('~') + '/.surprise_data/ml-100k/ml-100k/u1.test'\r\n",
        "    data = Dataset.load_from_folds([(train_file, test_file)], Reader('ml-100k'))\r\n",
        "\r\n",
        "    pkf = PredefinedKFold()\r\n",
        "    print(pkf)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "\r\n",
        "    for trainset, testset in pkf.split(data):\r\n",
        "        algo.fit(trainset)                             \r\n",
        "        predictions = algo.test(testset)\r\n",
        "        print(rmse(predictions))\r\n",
        "        print(\"\\n\")\r\n",
        "        print(mae(predictions))\r\n",
        "                                                                                \r\n",
        "        #dump.dump('./dump_file', predictions, algo)\r\n",
        "\r\n",
        "\r\n",
        "    user_prediction_pearson_bias = predict(train,sim_matrix)\r\n",
        "    #print(user_prediction_pearson_bias)\r\n",
        "    #print(test)\r\n",
        "    #print ('User-based CF MSE:(Pearson)' + str(get_rmse(user_prediction_pearson_bias, test)))\r\n",
        "    user_prediction_pearson_nobias = predict_nobias(train,sim_matrix)\r\n",
        "    #print ('User-based CF MSE:(Pearson)' + str(get_rmse(user_prediction_pearson_nobias, test)))\r\n",
        "    #print ('User-based CF MSE:(Pearson)' + str(get_mae(user_prediction_pearson_nobias, test)))\r\n",
        "    #mae_pb=compute_MAE(user_prediction_pearson_nobias, test)\r\n",
        "    #MAE_pb.append(mae_pb[0])\r\n",
        "    #print ('User-based CF MAE:(Pearson)' +str((compute_MAE(user_prediction_pearson_nobias, test))[0]))\r\n",
        "\r\n",
        "    user_prediction_pearson_nobias_topk = predict_topk(train,sim_matrix)\r\n",
        "    #print ('User-based CF MSE:(Pearson,TOP-K) without bias ' + str(get_rmse(user_prediction_pearson_nobias_topk, test)))\r\n",
        "    #print ('User-based CF MAE:(Pearson,TOP-K) without bias ' + str(get_mae(user_prediction_pearson_nobias_topk, test)))\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "split = \n",
            "0.3\n",
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "<surprise.model_selection.split.PredefinedKFold object at 0x7fd41d2d72d0>\n",
            "\n",
            "\n",
            "\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0205\n",
            "1.0205088226677514\n",
            "\n",
            "\n",
            "MAE:  0.8114\n",
            "0.8113987415916873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0b4512a58b52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#print(test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#print ('User-based CF MSE:(Pearson)' + str(get_rmse(user_prediction_pearson_bias, test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0muser_prediction_pearson_nobias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_nobias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m#print ('User-based CF MSE:(Pearson)' + str(get_rmse(user_prediction_pearson_nobias, test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#print ('User-based CF MSE:(Pearson)' + str(get_mae(user_prediction_pearson_nobias, test)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_nobias' is not defined"
          ]
        }
      ]
    }
  ]
}